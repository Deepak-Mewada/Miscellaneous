{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZxiXKAbpTGleDgscIozAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepak-Mewada/Miscellaneous/blob/main/Fashion_MNIST_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qDy7aPb81FjG"
      },
      "outputs": [],
      "source": [
        "\n",
        "#\n",
        "# Basic Datasets Question\n",
        "#\n",
        "# Create a classifier for the Fashion MNIST dataset\n",
        "# Note that the test will expect it to classify 10 classes and that the\n",
        "# input shape should be the native size of the Fashion MNIST dataset which is\n",
        "# 28x28 monochrome. Do not resize the data. Your input layer should accept\n",
        "# (28,28) as the input shape only. If you amend this, the tests will fail.\n",
        "#\n",
        "import tensorflow as tf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hsWx14Y1Q2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solution_model():\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "ytOsHwqL1JfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"mymodel.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Szo4IMHY1L2c",
        "outputId": "0b0b3b90-de3d-4c4e-bc1d-2a0f1ceb5e9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8b6309ac469f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# and the score will be returned to you.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolution_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mymodel.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'solution_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VqTP5KV92TI1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=50,\n",
        "    validation_data=ds_test,\n",
        ")\n",
        "\n",
        "model.save(\"mymodel1.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaVSgjD62ii0",
        "outputId": "0110650d-8fff-4a0d-b457-4a9ef4a7696e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 8s 6ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ======================================================================\n",
        "#\n",
        "# Basic Datasets Question\n",
        "#\n",
        "# Create and train a classifier for the MNIST dataset.\n",
        "# Note that the test will expect it to classify 10 classes and that the \n",
        "# input shape should be the native size of the MNIST dataset which is \n",
        "# 28x28 monochrome. Do not resize the data. Your input layer should accept\n",
        "# (28,28) as the input shape only. If you amend this, the tests will fail.\n",
        "#\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "class OutLayer(tf.keras.layers.Layer):\n",
        "    def _init_(self):\n",
        "        super(OutLayer, self)._init_()\n",
        "    def call(self, inputs):\n",
        "        return tf.expand_dims(inputs, 3)\n",
        "\n",
        "def solution_model():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "    training_images = training_images / 255.0\n",
        "    test_images = test_images / 255.0\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            min_delta=1e-4,\n",
        "            patience=3,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath='mymodel.h5',\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(OutLayer())\n",
        "    model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(13, 13, 16)))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(\n",
        "        training_images,\n",
        "        training_labels,\n",
        "        batch_size=128,\n",
        "        epochs=50,\n",
        "        verbose=1,\n",
        "        validation_data=(test_images, test_labels),\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    return model\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n"
      ],
      "metadata": {
        "id": "dt8q1xKc6V0k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = solution_model()\n",
        "model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b75F3BMZFg_9",
        "outputId": "e0dac8cd-8ce9-45ce-af1a-f00e0940057f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.3696 - accuracy: 0.8857\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97480, saving model to mymodel.h5\n",
            "469/469 [==============================] - 26s 54ms/step - loss: 0.3691 - accuracy: 0.8858 - val_loss: 0.0796 - val_accuracy: 0.9748\n",
            "Epoch 2/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.9684\n",
            "Epoch 2: val_accuracy improved from 0.97480 to 0.98250, saving model to mymodel.h5\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.1042 - accuracy: 0.9684 - val_loss: 0.0529 - val_accuracy: 0.9825\n",
            "Epoch 3/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9779\n",
            "Epoch 3: val_accuracy improved from 0.98250 to 0.98580, saving model to mymodel.h5\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.0753 - accuracy: 0.9779 - val_loss: 0.0434 - val_accuracy: 0.9858\n",
            "Epoch 4/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9819\n",
            "Epoch 4: val_accuracy improved from 0.98580 to 0.98690, saving model to mymodel.h5\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.0619 - accuracy: 0.9820 - val_loss: 0.0401 - val_accuracy: 0.9869\n",
            "Epoch 5/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9843\n",
            "Epoch 5: val_accuracy improved from 0.98690 to 0.98800, saving model to mymodel.h5\n",
            "469/469 [==============================] - 28s 59ms/step - loss: 0.0529 - accuracy: 0.9843 - val_loss: 0.0360 - val_accuracy: 0.9880\n",
            "Epoch 6/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9861\n",
            "Epoch 6: val_accuracy improved from 0.98800 to 0.98810, saving model to mymodel.h5\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.0369 - val_accuracy: 0.9881\n",
            "Epoch 7/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9876\n",
            "Epoch 7: val_accuracy improved from 0.98810 to 0.98890, saving model to mymodel.h5\n",
            "469/469 [==============================] - 25s 53ms/step - loss: 0.0412 - accuracy: 0.9876 - val_loss: 0.0336 - val_accuracy: 0.9889\n",
            "Epoch 8/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9893\n",
            "Epoch 8: val_accuracy improved from 0.98890 to 0.99090, saving model to mymodel.h5\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0277 - val_accuracy: 0.9909\n",
            "Epoch 9/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9902\n",
            "Epoch 9: val_accuracy did not improve from 0.99090\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0321 - val_accuracy: 0.9904\n",
            "Epoch 10/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9911\n",
            "Epoch 10: val_accuracy improved from 0.99090 to 0.99130, saving model to mymodel.h5\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.0290 - accuracy: 0.9910 - val_loss: 0.0291 - val_accuracy: 0.9913\n",
            "Epoch 11/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9921\n",
            "Epoch 11: val_accuracy improved from 0.99130 to 0.99190, saving model to mymodel.h5\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.0278 - val_accuracy: 0.9919\n",
            "Epoch 12/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9921\n",
            "Epoch 12: val_accuracy did not improve from 0.99190\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0317 - val_accuracy: 0.9903\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9932\n",
            "Epoch 13: val_accuracy did not improve from 0.99190\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.0348 - val_accuracy: 0.9896\n",
            "Epoch 14/50\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9936\n",
            "Epoch 14: val_accuracy did not improve from 0.99190\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0314 - val_accuracy: 0.9905\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ]
    }
  ]
}